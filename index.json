[{"authors":null,"categories":null,"content":"I am currently a Research Fellow at the Mullard Space Science Laboratory (MSSL), in the University College London (UCL) Space and Climate department. Recently, I completed my PhD at MSSL, where I was also awarded the Alan Johnstone Award for Outstanding Scientific Achievement. Prior to my doctoral studies I completed an MSci (BA) in Astrophysics (Physical Natural Sciences) at the University of Cambridge, where I was awarded a Clough Scholarship for academic excellence.\nMy research is focussed around the intersection of probability theory, applied mathematics, and artificial intelligence, with much of my current work aimed towards the development of novel hybrid techniques. Primarily, my scientific application domain is Cosmology, in particular the distillation of statistically principled information from Gravitational Lensing signatures. Due to the nature of astro-informatics, my research has found tangential applications in, e.g. geophysical imaging and medical imaging. Since 2017, I have been a full member of the Dark Energy Science Collaboration, and have held multiple internship positions with the pioneering technology start-up Kagenova.\n","date":1662681600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1662681600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://academic-demo.netlify.app/author/matthew-price/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/matthew-price/","section":"authors","summary":"I am currently a Research Fellow at the Mullard Space Science Laboratory (MSSL), in the University College London (UCL) Space and Climate department. Recently, I completed my PhD at MSSL, where I was also awarded the Alan Johnstone Award for Outstanding Scientific Achievement.","tags":null,"title":"Matthew Price","type":"authors"},{"authors":["Jeremy Ocampo","Matthew Price","Jason D. McEwen"],"categories":null,"content":"","date":1662681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662681600,"objectID":"2f9ed8a0ef65d853de124cbe818d7b33","permalink":"https://academic-demo.netlify.app/publication/disco_2022/","publishdate":"2022-09-09T00:00:00Z","relpermalink":"/publication/disco_2022/","section":"publication","summary":"No existing spherical convolutional neural network (CNN) framework is both computationally scalable and rotationally equivariant. Continuous approaches capture rotational equivariance but are often prohibitively computationally demanding. Discrete approaches offer more favorable computational performance but at the cost of equivariance. We develop a hybrid discrete-continuous (DISCO) group convolution that is simultaneously equivariant and computationally scalable to high-resolution. While our framework can be applied to any compact group, we specialize to the sphere. Our DISCO spherical convolutions not only exhibit SO(3) rotational equivariance but also a form of asymptotic SO(3)/SO(2) rotational equivariance, which is more desirable for many applications (where SO(n) is the special orthogonal group representing rotations in n-dimensions). Through a sparse tensor implementation we achieve linear scaling in number of pixels on the sphere for both computational cost and memory usage. For 4k spherical images we realize a saving of 109 in computational cost and 104 in memory usage when compared to the most efficient alternative equivariant spherical convolution. We apply the DISCO spherical CNN framework to a number of benchmark dense-prediction problems on the sphere, such as semantic segmentation and depth estimation, on all of which we achieve the state-of-the-art performance.","tags":["Machine Learning","Deep Learning","Harmonic Analysis"],"title":"Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO) Convolutions","type":"publication"},{"authors":["Alessio S. Mancini","Matthew M. Docherty","Matthew Price","Jason D. McEwen"],"categories":null,"content":"","date":1653350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653350400,"objectID":"cdd0b2a0f95ad2ac24fa05dc00fc42c0","permalink":"https://academic-demo.netlify.app/publication/harmonic_sbi_2022/","publishdate":"2022-05-24T00:00:00Z","relpermalink":"/publication/harmonic_sbi_2022/","section":"publication","summary":"Comparison of appropriate models to describe observational data is a fundamental task of science. The Bayesian model evidence, or marginal likelihood, is a computationally challenging, yet crucial, quantity to estimate to perform Bayesian model comparison. We introduce a methodology to compute the Bayesian model evidence in simulation-based inference (SBI) scenarios (also often called likelihood-free inference). In particular, we leverage the recently proposed learnt harmonic mean estimator and exploit the fact that it is decoupled from the method used to generate posterior samples, i.e. it requires posterior samples only, which may be generated by any approach. This flexibility, which is lacking in many alternative methods for computing the model evidence, allows us to develop SBI model comparison techniques for the three main neural density estimation approaches, including neural posterior estimation (NPE), neural likelihood estimation (NLE), and neural ratio estimation (NRE). We demonstrate and validate our SBI evidence calculation techniques on a range of inference problems, including a gravitational wave example. Moreover, we further validate the accuracy of the learnt harmonic mean estimator, implemented in the HARMONIC software, in likelihood-based settings. These results highlight the potential of HARMONIC as a sampler-agnostic method to estimate the model evidence in both likelihood-based and simulation-based scenarios.","tags":["Bayesian Inference","Machine Learning","Simulation based inference"],"title":"Bayesian model comparison for simulation-based inference","type":"publication"},{"authors":null,"categories":null,"content":"optimus-primal is a light weight proximal splitting Forward Backward Primal Dual based solver for convex optimization problems. The current version supports finding the minimum of $f(x) + h(A x) + p(B x) + g(x)$, where $f$, $h$, and $p$ are lower semi continuous and have proximal operators, and $g$ is differentiable. $A$ and $B$ are linear operators. To learn more about proximal operators and algorithms, visit proximity operator repository. We suggest that users read the tutorial \u0026ldquo;The Proximity Operator Repository. User\u0026rsquo;s guide\u0026rdquo;.\n","date":1639353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639353600,"objectID":"eab7d9f377352740af6f3f10369cfb0f","permalink":"https://academic-demo.netlify.app/codes/optimus-primal/","publishdate":"2021-12-13T00:00:00Z","relpermalink":"/codes/optimus-primal/","section":"codes","summary":"A light weight python package for proximal splitting Forward-backward Primal-dual based solver for convex optimisation problems.","tags":["Signal processing"],"title":"Optimus-Primal: A light weight primal-dual solver","type":"codes"},{"authors":null,"categories":null,"content":"We resurrect the infamous harmonic mean estimator for computing the marginal likelihood (Bayesian evidence) and solve its problematic large variance. The marginal likelihood is a key component of Bayesian model selection since it is required to evaluate model posterior probabilities; however, its computation is challenging. The original harmonic mean estimator, first proposed in 1994 by Newton and Raftery, involves computing the harmonic mean of the likelihood given samples from the posterior. It was immediately realised that the original estimator can fail catastrophically since its variance can become very large and may not be finite. A number of variants of the harmonic mean estimator have been proposed to address this issue although none have proven fully satisfactory.\nWe present the learnt harmonic mean estimator, a variant of the original estimator that solves its large variance problem. This is achieved by interpreting the harmonic mean estimator as importance sampling and introducing a new target distribution. The new target distribution is learned to approximate the optimal but inaccessible target, while minimising the variance of the resulting estimator. Since the estimator requires samples of the posterior only it is agnostic to the strategy used to generate posterior samples.\n","date":1639094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639094400,"objectID":"dca3b02d4ddc3901b7c51766f44d33de","permalink":"https://academic-demo.netlify.app/codes/harmonic/","publishdate":"2021-12-10T00:00:00Z","relpermalink":"/codes/harmonic/","section":"codes","summary":"A professional grade Python implementation of the learnt harmonic mean estimator (McEwen et al. 2021).","tags":["Machine learning","Bayesian evidence estimation","Probability theory"],"title":"harmonic: Learnt harmonic mean estimator for Bayesian model selection","type":"codes"},{"authors":null,"categories":null,"content":"FLAG is a fast implementation of the Fourier-Laguerre Transform, a novel 3-dimensional transform exploiting an exact quadrature rule of the ball to construct an exact harmonic transform in 3D spherical coordinates. The angular part of the Fourier-Laguerre transform uses the MW sampling theorem and the exact spherical harmonic transform implemented in the SSHT code. The radial sampling scheme arises from an exact quadrature of the radial half-line using damped Laguerre polynomials. The radial transform can in fact be used to compute the spherical Bessel transform exactly, and the Fourier-Laguerre transform is thus closely related to the Fourier-Bessel transform.\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"0a0ea41ea6fa0d59fe22aa476168cdc8","permalink":"https://academic-demo.netlify.app/codes/flag/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/codes/flag/","section":"codes","summary":"C/Python/Matlab package for fast and exact Fourier-Laguerre and Fourier-Bessel transforms on the ball.","tags":["Generalized Fourier Transforms","Ball Analysis"],"title":"FLAG: Fourier-LAGuerre Transform","type":"codes"},{"authors":null,"categories":null,"content":"The FLAGLET code provides high-performance routines for fast wavelet analysis of signals on the ball using the Flaglet transform described in Leistedt and McEwen (2012). It exploits S2LET, FLAG and SSHT codes. The flaglet transform is theoretically exact, i.e. the original signal can be synthesises from its wavelet coefficients exactly since the wavelet coefficients capture all the information of band-limited signals. The flaglets are constructed through an exact tilling of the Fourier-Laguerre space, a conjunction of the harmonic multipoles arising from the spherical harmonic transform on the sphere (performed by SSHT) and the spherical Laguerre transform on the radial half-line (performed in FLAG). This 2D harmonic space is tiled into wavelets (`flaglets') following the scale-discretised approach and its implementation in S2LET. The flaglets are highly localised in both real and frequency spaces, and form a dictionary in which most naturally occurring signals are sparse.\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"2d842f7e6ecaaf0fbd2c1b3f05331110","permalink":"https://academic-demo.netlify.app/codes/flaglet/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/codes/flaglet/","section":"codes","summary":"C/Python/Matlab package for fast and exact wavelet transform on the ball.","tags":["Generalized Fourier Transforms","Ball Analysis","Wavelets"],"title":"FLAGLET: Fourier-Laguerre Wavelets on the Ball","type":"codes"},{"authors":["Jason D. McEwen","Christopher G. R. Wallis","Matthew Price","Matthew M. Docherty"],"categories":null,"content":"","date":1637712000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637712000,"objectID":"7b2c32ce2e0a1056f3bac69985781a13","permalink":"https://academic-demo.netlify.app/publication/harmonic_2021/","publishdate":"2021-11-24T00:00:00Z","relpermalink":"/publication/harmonic_2021/","section":"publication","summary":"We resurrect the infamous harmonic mean estimator for computing the marginal likelihood (Bayesian evidence) and solve its problematic large variance. The marginal likelihood is a key component of Bayesian model selection since it is required to evaluate model posterior probabilities; however, its computation is challenging. The original harmonic mean estimator, first proposed in 1994 by Newton and Raftery, involves computing the harmonic mean of the likelihood given samples from the posterior. It was immediately realised that the original estimator can fail catastrophically since its variance can become very large and may not be finite. A number of variants of the harmonic mean estimator have been proposed to address this issue although none have proven fully satisfactory. We present the learnt harmonic mean estimator, a variant of the original estimator that solves its large variance problem. This is achieved by interpreting the harmonic mean estimator as importance sampling and introducing a new target distribution. The new target distribution is learned to approximate the optimal but inaccessible target, while minimising the variance of the resulting estimator. Since the estimator requires samples of the posterior only it is agnostic to the strategy used to generate posterior samples. We validate the estimator on a variety of numerical experiments, including a number of pathological examples where the original harmonic mean estimator fails catastrophically. In all cases our learnt harmonic mean estimator is shown to be highly accurate. The estimator is computationally scalable and can be applied to problems of dimension $\\mathcal{O}(10^3)$ and beyond. Code implementing the learnt harmonic mean estimator is made publicly available.","tags":["Bayesian Inference","Machine Learning"],"title":"Machine learning assisted Bayesian model comparison: learnt harmonic mean estimator","type":"publication"},{"authors":["Matthew Price"],"categories":null,"content":"This talk was given in receipt of the Alan Johnston Award for Outstanding Scientific Achievement in 2021 at the Mullard Space Science Laboratory (MSSL), Department of Space and Climate Physics, University College London (UCL). It contains a very high-level overview of some of the work that went into my doctoral thesis, with some (hopefully) interesting animations!\n","date":1637154000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637154000,"objectID":"953ac2c0de3a929a19345ead5ca488e6","permalink":"https://academic-demo.netlify.app/talks/example/","publishdate":"2021-12-15T00:00:00Z","relpermalink":"/talks/example/","section":"talks","summary":"Invited talk in receipt of the Alan Johnston Award for Outstanding Scientific Achievement (2021).","tags":[],"title":"Imaging the Invisible","type":"talks"},{"authors":["Christopher G. R. Wallis","Matthew Price","Jason D. McEwen","Thomas D. Kitching","Boris Leistedt","Antoine Plouviez"],"categories":null,"content":"  section { background: white; color: black; border-radius: 1em; padding: 1em; left: 50% } #inner { display: inline-block; display: flex; align-items: center; justify-content: center }           -- ","date":1636502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636502400,"objectID":"e4a7fb932ef38368434f783d2cba83a3","permalink":"https://academic-demo.netlify.app/publication/massmappy_2021/","publishdate":"2021-11-10T00:00:00Z","relpermalink":"/publication/massmappy_2021/","section":"publication","summary":"Convergence maps of the integrated matter distribution are a key science result from weak gravitational lensing surveys. To date, recovering convergence maps has been performed using a planar approximation of the celestial sphere. However, with the increasing area of sky covered by dark energy experiments, such as Euclid, the Vera Rubin Observatory’s Legacy Survey of Space and Time (LSST), and the Nancy Grace Roman Space Telescope, this assumption will no longer be valid. We recover convergence fields on the celestial sphere using an extension of the Kaiser–Squires estimator to the spherical setting. Through simulations, we study the error introduced by planar approximations. Moreover, we examine how best to recover convergence maps in the planar setting, considering a variety of different projections and defining the local rotations that are required when projecting spin fields such as cosmic shear. For the sky coverages typical of future surveys, errors introduced by projection effects can be of the order of tens of percent, exceeding 50% in some cases. The stereographic projection, which is conformal and so preserves local angles, is the most effective planar projection. In any case, these errors can be avoided entirely by recovering convergence fields directly on the celestial sphere. We apply the spherical Kaiser–Squires mass-mapping method presented to the public Dark Energy Survey science verification data to recover convergence maps directly on the celestial sphere.","tags":["Dark Matter","Signal Processing","Harmonic Analysis"],"title":"Mapping dark matter on the celestial sphere with weak gravitational lensing","type":"publication"},{"authors":["Matthew Price","Jason D. McEwen","Xiaohao Cai","Thomas D. Kitching","Christopher G. R. Wallis"],"categories":null,"content":"  section { background: white; color: black; border-radius: 1em; padding: 1em; left: 50% } #inner { display: inline-block; display: flex; align-items: center; justify-content: center }           -- ","date":1626048000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626048000,"objectID":"e77deb11ae2da88f08cf85f60ebeed88","permalink":"https://academic-demo.netlify.app/publication/hypothesis_testing_2021/","publishdate":"2021-07-12T00:00:00Z","relpermalink":"/publication/hypothesis_testing_2021/","section":"publication","summary":"A crucial aspect of mass mapping, via weak lensing, is quantification of the uncertainty introduced during the reconstruction process. Properly accounting for these errors has been largely ignored to date. We present a new method to reconstruct maximum a posteriori (MAP) convergence maps by formulating an unconstrained Bayesian inference problem with Laplace-type $\\ell_1$-norm sparsity-promoting priors, which we solve via convex optimization. Approaching mass mapping in this manner allows us to exploit recent developments in probability concentration theory to infer theoretically conservative uncertainties for our MAP reconstructions, without relying on assumptions of Gaussianity. For the first time, these methods allow us to perform hypothesis testing of structure, from which it is possible to distinguish between physical objects and artefacts of the reconstruction. Here, we present this new formalism, and demonstrate the method on simulations, before applying the developed formalism to two observational data sets of the Abell 520 cluster. Initial reconstructions of the Abell 520 catalogues reported the detection of an anomalous 'dark core' – an overdense region with no optical counterpart – which was taken to be evidence for self-interacting dark matter. In our Bayesian framework, it is found that neither Abell 520 data set can conclusively determine the physicality of such dark cores at 99% confidence. However, in both cases the recovered MAP estimators are consistent with both sets of data.","tags":["Dark Matter","Bayesian Inference","Signal Processing"],"title":"Sparse Bayesian mass-mapping with uncertainties: hypothesis testing of structure","type":"publication"},{"authors":["Matthew Price","Jason D. McEwen"],"categories":null,"content":"","date":1620777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620777600,"objectID":"0d6395a6b466d354af7a630f35b85a03","permalink":"https://academic-demo.netlify.app/publication/ball_imaging_2021/","publishdate":"2021-05-12T00:00:00Z","relpermalink":"/publication/ball_imaging_2021/","section":"publication","summary":"We develop variational regularisation methods which leverage sparsity-promoting priors to solve severely ill posed inverse problems defined on the 3D ball (i.e. the solid sphere). Our method solves the problem natively on the ball and thus does not suffer from discontinuities that plague alternate approaches where each spherical shell is considered independently. Additionally, we leverage advances in probability density theory to produce Bayesian variational methods which benefit from the computational efficiency of advanced convex optimisation algorithms, whilst supporting principled uncertainty quantification. We showcase these variational regularisation and uncertainty quantification techniques on an illustrative example. The C++ code discussed throughout is provided under a GNU general public license.","tags":["Bayesian Inference","Signal Processing","Ball Analysis"],"title":"Bayesian variational regularisation on the ball","type":"publication"},{"authors":["Matthew Price","Luke Pratley","Jason D. McEwen"],"categories":null,"content":"","date":1620691200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620691200,"objectID":"b5a0490cc6e6bffbcce02cbe8314e572","permalink":"https://academic-demo.netlify.app/publication/spherical_reconstruction_2021/","publishdate":"2021-05-11T00:00:00Z","relpermalink":"/publication/spherical_reconstruction_2021/","section":"publication","summary":"Inverse problems defined naturally on the sphere are becoming increasingly of interest. In this article we provide a general framework for evaluation of inverse problems on the sphere, with a strong emphasis on flexibility and scalability. We consider flexibility with respect to the prior selection (regularisation), the problem definition - specifically the problem formulation (constrained/unconstrained) and problem setting (analysis/synthesis) - and optimisation adopted to solve the problem. We discuss and quantify the trade-offs between problem formulation and setting. Crucially, we consider the Bayesian interpretation of the unconstrained problem which, combined with recent developments in probability density theory, permits rapid, statistically principled uncertainty quantification (UQ) in the spherical setting. Linearity is exploited to significantly increase the computational efficiency of such UQ techniques, which in some cases are shown to permit analytic solutions. We showcase this reconstruction framework and UQ techniques on a variety of spherical inverse problems. The code discussed throughout is provided under a GNU general public license, in both C++ and Python.","tags":["Bayesian Inference","Signal Processing","Harmonic Analysis"],"title":"Sparse image reconstruction on the sphere: a general approach with uncertainty quantification","type":"publication"},{"authors":["Matthew Price","Jason D. McEwen","Luke Pratley","Thomas D. Kitching"],"categories":null,"content":"  section { background: white; color: black; border-radius: 1em; padding: 1em; left: 50% } #inner { display: inline-block; display: flex; align-items: center; justify-content: center }           -- ","date":1605571200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605571200,"objectID":"277e74bd06242d6387c57e91c1d8cae0","permalink":"https://academic-demo.netlify.app/publication/spherical_massmapping_2021/","publishdate":"2020-11-17T00:00:00Z","relpermalink":"/publication/spherical_massmapping_2021/","section":"publication","summary":"To date weak gravitational lensing surveys have typically been restricted to small fields of view, such that the flat-sky approximation has been sufficiently satisfied. However, with Stage IV surveys (e.g. LSST and Euclid) imminent, extending mass-mapping techniques to the sphere is a fundamental necessity. As such, we extend the sparse hierarchical Bayesian mass-mapping formalism presented in previous work to the spherical sky. For the first time, this allows us to construct maximum a posteriori spherical weak lensing dark-matter mass-maps, with principled Bayesian uncertainties, without imposing or assuming Gaussianty. We solve the spherical mass-mapping inverse problem in the analysis setting adopting a sparsity promoting Laplace-type wavelet prior, though this theoretical framework supports all log-concave posteriors. Our spherical mass-mapping formalism facilitates principled statistical interpretation of reconstructions. We apply our framework to convergence reconstruction on high resolution N-body simulations with pseudo-Euclid masking, polluted with a variety of realistic noise levels, and show a significant increase in reconstruction fidelity compared to standard approaches. Furthermore, we perform the largest joint reconstruction to date of the majority of publicly available shear observational data sets (combining DESY1, KiDS450, and CFHTLens) and find that our formalism recovers a convergence map with significantly enhanced small-scale detail. Within our Bayesian framework we validate, in a statistically rigorous manner, the community’s intuition regarding the need to smooth spherical Kaiser-Squires estimates to provide physically meaningful convergence maps. Such approaches cannot reveal the small-scale physical structures that we recover within our framework.","tags":["Dark Matter","Bayesian Inference","Signal Processing","Harmonic Analysis"],"title":"Sparse Bayesian mass-mapping with uncertainties: Full sky observations on the celestial sphere","type":"publication"},{"authors":["Oliver J. Cobb","Christopher G. R. Wallis","Augustine Mavor-Parker","Augustin Marignier","Matthew Price","Mayeul d'Avezac","Jason D. McEwen"],"categories":null,"content":"","date":1602201600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602201600,"objectID":"27c0cc3cf56496764ca0c8c4c7fcf437","permalink":"https://academic-demo.netlify.app/publication/spherical_cnns_2021/","publishdate":"2020-10-09T00:00:00Z","relpermalink":"/publication/spherical_cnns_2021/","section":"publication","summary":"Many problems across computer vision and the natural sciences require the analysis of spherical data, for which representations may be learned efficiently by encoding equivariance to rotational symmetries. We present a generalized spherical CNN framework that encompasses various existing approaches and allows them to be leveraged alongside each other. The only existing non-linear spherical CNN layer that is strictly equivariant has complexity $\\mathcal{O}(C^2L^5)$, where $C$ is a measure of representational capacity and $L$ the spherical harmonic bandlimit. Such a high computational cost often prohibits the use of strictly equivariant spherical CNNs. We develop two new strictly equivariant layers with reduced complexity $\\mathcal{O}(CL^4)$ and $\\mathcal{O}(CL^3 \\log L)$, making larger, more expressive models computationally feasible. Moreover, we adopt efficient sampling theory to achieve further computational savings. We show that these developments allow the construction of more expressive hybrid models that achieve state-of-the-art accuracy and parameter efficiency on spherical benchmark problems.","tags":["Machine Learning","Deep Learning","Harmonic Analysis"],"title":"Efficient generalized spherical CNNs","type":"publication"},{"authors":["Jason D. McEwen","Matthew Price"],"categories":null,"content":"","date":1593993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593993600,"objectID":"730b755e10aad3ab929fb51e6be3cafa","permalink":"https://academic-demo.netlify.app/publication/ridgelets_2019/","publishdate":"2020-07-06T00:00:00Z","relpermalink":"/publication/ridgelets_2019/","section":"publication","summary":"We revisit the spherical Radon transform, also called the Funk-Radon transform, viewing it as an axisymmetric convolution on the sphere. Viewing the spherical Radon transform in this manner leads to a straightforward derivation of its spherical harmonic representation, from which we show the spherical Radon transform can be inverted exactly for signals exhibiting antipodal symmetry. We then construct a spherical ridgelet transform by composing the spherical Radon and scale-discretised wavelet transforms on the sphere. The resulting spherical ridgelet transform also admits exact inversion for antipodal signals. The restriction to antipodal signals is expected since the spherical Radon and ridgelet transforms themselves result in signals that exhibit antipodal symmetry. Our ridgelet transform is defined natively on the sphere, probes signal content globally along great circles, does not exhibit blocking artefacts, supports spin signals and exhibits an exact and explicit inverse transform. No alternative ridgelet construction on the sphere satisfies all of these properties. Our implementation of the spherical Radon and ridgelet transforms is made publicly available. Finally, we illustrate the effectiveness of spherical ridgelets for diffusion magnetic resonance imaging of white matter fibers in the brain.","tags":["Wavelets","Harmonic Analysis","Signal Processing"],"title":"Scale-discretised ridgelet transform on the sphere","type":"publication"},{"authors":["Matthew Price","Xiaohao Cai","Jason D. McEwen","Marcelo Pereyra","Thomas D. Kitching"],"categories":null,"content":"  section { background: white; color: black; border-radius: 1em; padding: 1em; left: 50% } #inner { display: inline-block; display: flex; align-items: center; justify-content: center }           -- ","date":1575936000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575936000,"objectID":"5fccc1f4ac2ba50058895137bb84e76f","permalink":"https://academic-demo.netlify.app/publication/local_credible_intervals_2019/","publishdate":"2019-12-10T00:00:00Z","relpermalink":"/publication/local_credible_intervals_2019/","section":"publication","summary":"Until recently, mass-mapping techniques for weak gravitational lensing convergence reconstruction have lacked a principled statistical framework upon which to quantify reconstruction uncertainties, without making strong assumptions of Gaussianity. In previous work, we presented a sparse hierarchical Bayesian formalism for convergence reconstruction that addresses this shortcoming. Here, we draw on the concept of local credible intervals (cf. Bayesian error bars) as an extension of the uncertainty quantification techniques previously detailed. These uncertainty quantification techniques are benchmarked against those recovered via Px-MALA – a state-of-the-art proximal Markov chain Monte Carlo (MCMC) algorithm. We find that, typically, our recovered uncertainties are everywhere conservative (never underestimate the uncertainty, yet the approximation error is bounded above), of similar magnitude and highly correlated with those recovered via Px-MALA. Moreover, we demonstrate an increase in computational efficiency of $\\mathcal{O}(10^6)$ when using our sparse Bayesian approach over MCMC techniques. This computational saving is critical for the application of Bayesian uncertainty quantification to large-scale stage IV surveys such as LSST and Euclid.","tags":["Dark Matter","Bayesian Inference","Signal Processing","Proximal Sampling Methods"],"title":"Sparse Bayesian mass-mapping with uncertainties: local credible intervals","type":"publication"},{"authors":["Matthew Price","Xiaohao Cai","Jason D. McEwen","Thomas D. Kitching"],"categories":null,"content":"  section { background: white; color: black; border-radius: 1em; padding: 1em; left: 50% } #inner { display: inline-block; display: flex; align-items: center; justify-content: center }           -- ","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566777600,"objectID":"2a4966f824d54c94687a5189c4be16d9","permalink":"https://academic-demo.netlify.app/publication/peaks_2019/","publishdate":"2019-08-26T00:00:00Z","relpermalink":"/publication/peaks_2019/","section":"publication","summary":"Weak lensing convergence maps – upon which higher order statistics can be calculated – can be recovered from observations of the shear field by solving the lensing inverse problem. For typical surveys this inverse problem is ill-posed (often seriously) leading to substantial uncertainty on the recovered convergence maps. In this paper we propose novel methods for quantifying the Bayesian uncertainty in the location of recovered features and the uncertainty in the cumulative peak statistic – the peak count as a function of signal-to-noise ratio (SNR). We adopt the sparse hierarchical Bayesian mass-mapping framework developed in previous work, which provides robust reconstructions and principled statistical interpretation of reconstructed convergence maps without the need to assume or impose Gaussianity. We demonstrate our uncertainty quantification techniques on both Bolshoi N-body (cluster scale) and Buzzard V-1.6 (large-scale structure) N-body simulations. For the first time, this methodology allows one to recover approximate Bayesian upper and lower limits on the cumulative peak statistic at well-defined confidence levels.","tags":["Dark Matter","Bayesian Inference","Signal Processing"],"title":"Sparse Bayesian mass-mapping with uncertainties: peak statistics and feature locations","type":"publication"},{"authors":[],"categories":[],"content":" function detectBrowser() { var slashIndex = window.location.href.lastIndexOf(\"/\"); var cropped = window.location.href.slice(0,slashIndex+1); window.location.replace(cropped + \"assets/player/KeynoteDHTMLPlayer.html\"); }   ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"4a0111333fd051d0a7e3b733f17d8cdf","permalink":"https://academic-demo.netlify.app/slides/imaging_the_invisible_2021/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/imaging_the_invisible_2021/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Matthew Price","Jason D. McEwen","Xiaohao Cai","Thomas D. Kitching","Christopher G. R. Wallis","Marcelo Pereyra"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"271ac939575c21ce09a79acd271ada96","permalink":"https://academic-demo.netlify.app/publication/basp_2019/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/publication/basp_2019/","section":"publication","summary":"Mass-mapping via weak gravitational lensing has until recently lacked principled statistical consideration of uncertainties introduced during the reconstruction process – solving of an often seriously ill-posed inverse problem. In recent work we posed the mass-mapping inverse problem as an unconstrained Bayesian inference problem with Laplace-type $\\ell_1$-norm sparsity-promoting prior, which we solve via convex optimisation. Formulating the problem in this way allows us to exploit recent developments in probability concentration theory to infer tightly bound, theoretically conservative uncertainties $\\mathcal{O}(10^6)$ times faster than traditional MCMC techniques. Building on these new fast Bayesian inference techniques we have developed several uncertainty quantification techniques primarily aimed towards the gravitational lensing paradigm, though entirely generalizable to other settings. The uncertainty quantification techniques reviewed here are; knock-out hypothesis testing of structure, local credible regions (cf. pixel-level Bayesian error bars), and Bayesian locational uncertainty of structure. Additionally, these conservative Bayesian inferences can be leveraged to aggregate uncertainties which are often computed by the weak lensing community (e.g. peak statistics).","tags":["Dark Matter","Bayesian Inference","Signal Processing"],"title":"Sparse Bayesian mass-mapping with uncertainties","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://academic-demo.netlify.app/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]